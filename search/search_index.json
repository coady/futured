{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Futured provides a consistent interface for concurrent functional programming in Python. It wraps any callable to return a <code>concurrent.futures.Future</code>, wraps any async coroutine with a compatible <code>Task</code> interface, and provides concurrent iterators and context managers for futures.</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#threaded-processed","title":"threaded, processed","text":"<p>Transform any callable into one which runs in a thread or process pool, and returns a future.</p> <pre><code>from futured import threaded, processed\nimport httpx\n\nfetch = threaded(httpx.Client().get)\nfetch(url)  # return Future\n\nfs = (fetch(url + path) for path in paths)\nthreaded.results(fs)  # generate results from futures\nthreaded.results(fs, timeout=...)  # generate results as completed\n\nfetch.map(urls)  # generate results in order\nfetch.map(urls, timeout=...)  # generate results as completed\nfetch.mapzip(urls)  # generate (url, result) pairs as completed\n</code></pre> <p>Thread and process pool executors may be used as context managers, customized with options, and reused with different callables.</p> <pre><code>threaded(max_workers=...)(func, ...)\nprocessed(max_workers=...)(func, ...)\n</code></pre> <p><code>futured</code> classes have a <code>waiting</code> context manager which collects results from tasks. Futures can be registered at creation, or appended to the list of tasks.</p> <pre><code>with threaded.waiting(*fs) as tasks:\n    tasks.append(future)\ntasks  # list of completed results\n</code></pre> <p><code>futured</code> classes provide a <code>tasks</code> interface which generalizes <code>futures.as_completed</code> and <code>futures.wait</code>, while allowing the set of tasks to be modified, e.g., for retries.</p> <pre><code>threaded.tasks(fs, timeout=...)  # mutable set of running tasks which iterate as completed\n</code></pre>"},{"location":"#asynced","title":"asynced","text":"<p>The same interface works for <code>asyncio</code>.</p> <pre><code>from futured import asynced\nimport httpx\n\nfetch = asynced(httpx.AsyncClient().get)\nfetch(url)  # return coroutine\n\nasynced.results(fs)  # generate results from futures\nasynced.results(fs, timeout=...)  # generate results as completed\n\nfetch.map(urls)  # generate results in order\nfetch.map(urls, timeout=...)  # generate results as completed\nfetch.mapzip(urls)  # generate (url, result) pairs as completed\n</code></pre> <p><code>asynced</code> provides utilities for calling coroutines from a synchronous context. <code>waiting</code> is similar to trio's nursery, but returns results from a synchronous <code>with</code> block.</p> <pre><code>asynced.run(async_func, ...)  # call and run until complete\nasynced.run(async_gen, ...)  # call and run synchronous iterator\nwith asynced.waiting(*fs) as tasks:  # concurrent coroutines completed in a block\nasynced.tasks(fs, timeout=...)  # mutable set of running tasks which iterate as completed\n</code></pre>"},{"location":"#extensions","title":"extensions","text":"<p>There is also support for dask distributed clients and gevent greenlets.</p> <pre><code>from futured import distributed, greened\n</code></pre>"},{"location":"#decorators","title":"decorators","text":"<p>Naturally <code>futured</code> wrappers can be used as decorators, but arguments can also be partially bound.</p> <pre><code>@threaded\ndef slow():\n   ...\n\nfetch = threaded(httpx.Client().get, url)\nfetch(params=...)\n</code></pre> <p>Methods are supported, as well as a <code>decorated</code> utility for automatically subclassing.</p> <pre><code>from futured import decorated\n\nFutureClient = decorated(httpx.Client, request=threaded)\n\n # equivalent to\nclass FutureClient(httpx.Client):\n    request = threaded(httpx.Client.request)\n</code></pre>"},{"location":"#command","title":"command","text":"<p><code>command</code> wraps <code>subprocess.Popen</code> to provide a <code>Future</code> compatible interface.</p> <pre><code>from futured import futured, command\n\ncommand('ls').result()  # return stdout or raises stderr\ncommand('ls').pipe('wc')  # pipes into next command, or | ('wc',... )\nfor line in command('ls'):  # iterable lines\ncommand.coroutine('ls')  # return coroutine\n\nfutured(command, 'ls')  # supports `map` interface\nasynced(command.coroutine, 'ls')  # supports `map` interface with timeout\n</code></pre>"},{"location":"#forked","title":"forked","text":"<p><code>forked</code> allows iteration in separate child processes.</p> <pre><code>from futured import forked\n\nfor value in forked(values, max_workers=...):\n    # in a child process\n # in parent after children have exited\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install futured\n</code></pre>"},{"location":"#tests","title":"Tests","text":"<p>100% branch coverage.</p> <pre><code>pytest [--cov]\n</code></pre>"},{"location":"examples/","title":"Examples","text":"In\u00a0[8]: Copied! <pre>from concurrent import futures\nimport httpx\n\nurls = [f'https://httpbin.org/delay/{d}' for d in (0.6, 0.3, 0.0)]\n\n\ndef fetch_all(urls):\n    with httpx.Client() as client, futures.ThreadPoolExecutor() as executor:\n        fs = [executor.submit(client.get, url) for url in urls]\n        for future in futures.as_completed(fs):\n            yield future.result()\n\n\nfor resp in fetch_all(urls):\n    print(resp.url)\n</pre> from concurrent import futures import httpx  urls = [f'https://httpbin.org/delay/{d}' for d in (0.6, 0.3, 0.0)]   def fetch_all(urls):     with httpx.Client() as client, futures.ThreadPoolExecutor() as executor:         fs = [executor.submit(client.get, url) for url in urls]         for future in futures.as_completed(fs):             yield future.result()   for resp in fetch_all(urls):     print(resp.url) <pre>https://httpbin.org/delay/0.0\nhttps://httpbin.org/delay/0.3\nhttps://httpbin.org/delay/0.6\n</pre> <p><code>futured.threaded</code> abstracts away the boilerplate.</p> In\u00a0[9]: Copied! <pre>from futured import threaded\n\nfetch = threaded(httpx.Client().get)\nfor resp in fetch.map(urls, as_completed=True):\n    print(resp.url)\n</pre> from futured import threaded  fetch = threaded(httpx.Client().get) for resp in fetch.map(urls, as_completed=True):     print(resp.url) <pre>https://httpbin.org/delay/0.0\nhttps://httpbin.org/delay/0.3\nhttps://httpbin.org/delay/0.6\n</pre> In\u00a0[10]: raises-exception Copied! <pre>import asyncio\nimport httpx\n\n\nasync def fetch_all(urls):\n    async with httpx.AsyncClient() as client:\n        for future in asyncio.as_completed(map(client.get, urls)):\n            yield await future\n\n\nfor resp in fetch_all(urls):\n    print(resp.url)\n</pre> import asyncio import httpx   async def fetch_all(urls):     async with httpx.AsyncClient() as client:         for future in asyncio.as_completed(map(client.get, urls)):             yield await future   for resp in fetch_all(urls):     print(resp.url) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[10], line 11\n      7         for future in asyncio.as_completed(map(client.get, urls)):\n      8             yield await future\n---&gt; 11 for resp in fetch_all(urls):\n     12     print(resp.url)\n\nTypeError: 'async_generator' object is not iterable</pre> <p>The problem is coroutines support the <code>yield</code> keyword, but only to create async iterators.  Even though <code>asyncio.as_completed</code> is itself a normal iterator, there is no way to write this generator as intended.  Additionally there is no iterator equivalent of <code>loop.run_until_complete</code>, to mitigate the viral nature of the <code>async</code> keyword.</p> <p>So <code>futured.asynced</code> provides one.</p> In\u00a0[\u00a0]: Copied! <pre>from futured import asynced\n\nfor resp in asynced.run(fetch_all, urls):\n    print(resp.url)\n</pre> from futured import asynced  for resp in asynced.run(fetch_all, urls):     print(resp.url) <p>The alternative approach is to explicitly handle the loop in the implementation.</p> In\u00a0[\u00a0]: Copied! <pre>def fetch_all(urls):\n    loop = asyncio.new_event_loop()\n    client = httpx.AsyncClient()\n    pending = [loop.create_task(client.get(url)) for url in urls]\n    while pending:\n        done, pending = loop.run_until_complete(\n            asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)\n        )\n        for future in done:\n            yield future.result()\n    loop.run_until_complete(client.aclose())\n\n\nfor resp in fetch_all(urls):\n    print(resp.url)\n</pre> def fetch_all(urls):     loop = asyncio.new_event_loop()     client = httpx.AsyncClient()     pending = [loop.create_task(client.get(url)) for url in urls]     while pending:         done, pending = loop.run_until_complete(             asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)         )         for future in done:             yield future.result()     loop.run_until_complete(client.aclose())   for resp in fetch_all(urls):     print(resp.url) <p>For this case, <code>asynced</code> provides the same abstraction as <code>threaded</code>.</p> In\u00a0[\u00a0]: Copied! <pre>fetch = asynced(httpx.AsyncClient().get)\nfor resp in fetch.map(urls, as_completed=True):\n    print(resp.url)\n</pre> fetch = asynced(httpx.AsyncClient().get) for resp in fetch.map(urls, as_completed=True):     print(resp.url)"},{"location":"examples/#examples","title":"Examples\u00b6","text":"<p>Fetching urls concurrently, and processing the responses as completed, is used as an example.  This simple task is nonetheless suprisingly tedious, especially using <code>asyncio</code>.</p>"},{"location":"examples/#threaded","title":"Threaded\u00b6","text":""},{"location":"examples/#asynced","title":"Asynced\u00b6","text":""},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#futured.futured","title":"<code>futured.futured</code>","text":"<p>               Bases: <code>partial</code></p> <p>A partial function which returns futures.</p> Source code in <code>futured/__init__.py</code> <pre><code>class futured(partial):\n    \"\"\"A partial function which returns futures.\"\"\"\n\n    as_completed: Callable = NotImplemented  # type: ignore\n\n    def __get__(self, instance, owner):\n        return self if instance is None else types.MethodType(self, instance)\n\n    @classmethod\n    def results(cls, fs: Iterable, *, as_completed=False, **kwargs) -&gt; Iterator:\n        \"\"\"Generate results concurrently from futures, by default in order.\n\n        Args:\n            fs: iterable of futures\n            as_completed kwargs: generate results as completed with options, e.g., timeout\n        \"\"\"\n        tasks = cls.as_completed(fs, **kwargs) if (as_completed or kwargs) else list(fs)\n        return map(operator.methodcaller('result'), tasks)\n\n    @classmethod\n    def items(cls, pairs: Iterable, **kwargs) -&gt; Iterator:\n        \"\"\"Generate key, result pairs as completed from futures.\n\n        Args:\n            pairs: key, future pairs\n            **kwargs: as completed options, e.g., timeout\n        \"\"\"\n        keys = dict(map(reversed, pairs))\n        return ((keys[future], future.result()) for future in cls.as_completed(keys, **kwargs))\n\n    def map(self, *iterables: Iterable, **kwargs) -&gt; Iterator:\n        \"\"\"Asynchronously map function.\n\n        Args:\n            **kwargs: keyword options for [results][futured.futured.results]\n        \"\"\"\n        return self.results(map(self, *iterables), **kwargs)\n\n    def starmap(self, iterable: Iterable, **kwargs) -&gt; Iterator:\n        \"\"\"Asynchronously starmap function.\n\n        Args:\n            **kwargs: keyword options for [results][futured.futured.results]\n        \"\"\"\n        return self.results(itertools.starmap(self, iterable), **kwargs)\n\n    def mapzip(self, iterable: Iterable, **kwargs) -&gt; Iterator:\n        \"\"\"Generate arg, result pairs as completed.\n\n        Args:\n            **kwargs: keyword options for [items][futured.futured.items]\n        \"\"\"\n        return self.items(((arg, self(arg)) for arg in iterable), **kwargs)\n\n    @classmethod\n    @contextlib.contextmanager\n    def waiting(cls, *fs, **kwargs):\n        \"\"\"Return context manager which waits on [results][futured.futured.results].\"\"\"\n        fs = list(fs)\n        try:\n            yield fs\n        finally:\n            fs[:] = cls.results(fs, **kwargs)\n\n    class tasks(set):\n        \"\"\"A set of futures which iterate as completed, and can be updated while iterating.\"\"\"\n\n        TimeoutError = futures.TimeoutError\n\n        def __init__(self, fs: Iterable, *, timeout=None):\n            super().__init__(fs)\n            self.timeout = timeout\n            self.it = self.iter()\n\n        def wait(self, fs: list) -&gt; Iterable:\n            return futures.wait(fs, self.timeout, return_when='FIRST_COMPLETED').done\n\n        def iter(self):\n            while self:\n                done = self.wait(list(super().__iter__()))\n                if not done:\n                    raise self.TimeoutError\n                self.difference_update(done)\n                yield from done\n\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            return next(self.it)\n</code></pre>"},{"location":"reference/#futured.futured.tasks","title":"<code>tasks</code>","text":"<p>               Bases: <code>set</code></p> <p>A set of futures which iterate as completed, and can be updated while iterating.</p> Source code in <code>futured/__init__.py</code> <pre><code>class tasks(set):\n    \"\"\"A set of futures which iterate as completed, and can be updated while iterating.\"\"\"\n\n    TimeoutError = futures.TimeoutError\n\n    def __init__(self, fs: Iterable, *, timeout=None):\n        super().__init__(fs)\n        self.timeout = timeout\n        self.it = self.iter()\n\n    def wait(self, fs: list) -&gt; Iterable:\n        return futures.wait(fs, self.timeout, return_when='FIRST_COMPLETED').done\n\n    def iter(self):\n        while self:\n            done = self.wait(list(super().__iter__()))\n            if not done:\n                raise self.TimeoutError\n            self.difference_update(done)\n            yield from done\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        return next(self.it)\n</code></pre>"},{"location":"reference/#futured.futured.items","title":"<code>items(pairs, **kwargs)</code>  <code>classmethod</code>","text":"<p>Generate key, result pairs as completed from futures.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>Iterable</code> <p>key, future pairs</p> required <code>**kwargs</code> <p>as completed options, e.g., timeout</p> <code>{}</code> Source code in <code>futured/__init__.py</code> <pre><code>@classmethod\ndef items(cls, pairs: Iterable, **kwargs) -&gt; Iterator:\n    \"\"\"Generate key, result pairs as completed from futures.\n\n    Args:\n        pairs: key, future pairs\n        **kwargs: as completed options, e.g., timeout\n    \"\"\"\n    keys = dict(map(reversed, pairs))\n    return ((keys[future], future.result()) for future in cls.as_completed(keys, **kwargs))\n</code></pre>"},{"location":"reference/#futured.futured.map","title":"<code>map(*iterables, **kwargs)</code>","text":"<p>Asynchronously map function.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>keyword options for results</p> <code>{}</code> Source code in <code>futured/__init__.py</code> <pre><code>def map(self, *iterables: Iterable, **kwargs) -&gt; Iterator:\n    \"\"\"Asynchronously map function.\n\n    Args:\n        **kwargs: keyword options for [results][futured.futured.results]\n    \"\"\"\n    return self.results(map(self, *iterables), **kwargs)\n</code></pre>"},{"location":"reference/#futured.futured.mapzip","title":"<code>mapzip(iterable, **kwargs)</code>","text":"<p>Generate arg, result pairs as completed.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>keyword options for items</p> <code>{}</code> Source code in <code>futured/__init__.py</code> <pre><code>def mapzip(self, iterable: Iterable, **kwargs) -&gt; Iterator:\n    \"\"\"Generate arg, result pairs as completed.\n\n    Args:\n        **kwargs: keyword options for [items][futured.futured.items]\n    \"\"\"\n    return self.items(((arg, self(arg)) for arg in iterable), **kwargs)\n</code></pre>"},{"location":"reference/#futured.futured.results","title":"<code>results(fs, *, as_completed=False, **kwargs)</code>  <code>classmethod</code>","text":"<p>Generate results concurrently from futures, by default in order.</p> <p>Parameters:</p> Name Type Description Default <code>fs</code> <code>Iterable</code> <p>iterable of futures</p> required <code>as_completed kwargs</code> <p>generate results as completed with options, e.g., timeout</p> required Source code in <code>futured/__init__.py</code> <pre><code>@classmethod\ndef results(cls, fs: Iterable, *, as_completed=False, **kwargs) -&gt; Iterator:\n    \"\"\"Generate results concurrently from futures, by default in order.\n\n    Args:\n        fs: iterable of futures\n        as_completed kwargs: generate results as completed with options, e.g., timeout\n    \"\"\"\n    tasks = cls.as_completed(fs, **kwargs) if (as_completed or kwargs) else list(fs)\n    return map(operator.methodcaller('result'), tasks)\n</code></pre>"},{"location":"reference/#futured.futured.starmap","title":"<code>starmap(iterable, **kwargs)</code>","text":"<p>Asynchronously starmap function.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>keyword options for results</p> <code>{}</code> Source code in <code>futured/__init__.py</code> <pre><code>def starmap(self, iterable: Iterable, **kwargs) -&gt; Iterator:\n    \"\"\"Asynchronously starmap function.\n\n    Args:\n        **kwargs: keyword options for [results][futured.futured.results]\n    \"\"\"\n    return self.results(itertools.starmap(self, iterable), **kwargs)\n</code></pre>"},{"location":"reference/#futured.futured.waiting","title":"<code>waiting(*fs, **kwargs)</code>  <code>classmethod</code>","text":"<p>Return context manager which waits on results.</p> Source code in <code>futured/__init__.py</code> <pre><code>@classmethod\n@contextlib.contextmanager\ndef waiting(cls, *fs, **kwargs):\n    \"\"\"Return context manager which waits on [results][futured.futured.results].\"\"\"\n    fs = list(fs)\n    try:\n        yield fs\n    finally:\n        fs[:] = cls.results(fs, **kwargs)\n</code></pre>"},{"location":"reference/#futured.threaded","title":"<code>futured.threaded</code>","text":"<p>               Bases: <code>executed</code></p> <p>A partial function executed in its own thread pool.</p> Source code in <code>futured/__init__.py</code> <pre><code>class threaded(executed):\n    \"\"\"A partial function executed in its own thread pool.\"\"\"\n\n    Executor = futures.ThreadPoolExecutor\n</code></pre>"},{"location":"reference/#futured.processed","title":"<code>futured.processed</code>","text":"<p>               Bases: <code>executed</code></p> <p>A partial function executed in its own process pool.</p> Source code in <code>futured/__init__.py</code> <pre><code>class processed(executed):\n    \"\"\"A partial function executed in its own process pool.\"\"\"\n\n    Executor = futures.ProcessPoolExecutor\n</code></pre>"},{"location":"reference/#futured.asynced","title":"<code>futured.asynced</code>","text":"<p>               Bases: <code>futured</code></p> <p>A partial async coroutine.</p> Source code in <code>futured/__init__.py</code> <pre><code>class asynced(futured):\n    \"\"\"A partial async coroutine.\"\"\"\n\n    @classmethod\n    def results(cls, fs: Iterable, *, as_completed=False, **kwargs) -&gt; Iterator:\n        if as_completed or kwargs:\n            return map(operator.methodcaller('result'), cls.tasks(fs, **kwargs))\n        loop = asyncio.new_event_loop()\n        tasks = list(map(loop.create_task, fs))\n        return map(loop.run_until_complete, tasks)\n\n    @staticmethod\n    async def pair(key, future):\n        return key, await future\n\n    @classmethod\n    def items(cls, pairs: Iterable, **kwargs) -&gt; Iterator:\n        return cls.results(itertools.starmap(cls.pair, pairs), as_completed=True, **kwargs)\n\n    def run(self: Callable, *args, **kwargs):\n        \"\"\"Synchronously call and run coroutine or asynchronous iterator.\"\"\"\n        coro = self(*args, **kwargs)\n        return asynced.iter(coro) if isinstance(coro, AsyncIterable) else asyncio.run(coro)\n\n    @staticmethod\n    def iter(aiterable: AsyncIterable, loop=None):\n        \"\"\"Wrap an asynchronous iterable into an iterator.\n\n        Analogous to `asyncio.run` for coroutines.\n        \"\"\"\n        loop = loop or asyncio.new_event_loop()\n        anext = aiterable.__aiter__().__anext__\n        task = loop.create_task(anext())\n        while True:\n            try:\n                result = loop.run_until_complete(task)\n            except StopAsyncIteration:\n                return\n            task = loop.create_task(anext())\n            yield result\n\n    class tasks(futured.tasks):\n        __doc__ = futured.tasks.__doc__\n        TimeoutError = asyncio.TimeoutError\n\n        def __init__(self, coros: Iterable, **kwargs):\n            self.loop = asyncio.new_event_loop()\n            super().__init__(map(self.loop.create_task, coros), **kwargs)\n\n        def add(self, coro):\n            super().add(self.loop.create_task(coro))\n\n        def wait(self, fs: list) -&gt; Iterable:\n            coro = asyncio.wait(fs, timeout=self.timeout, return_when='FIRST_COMPLETED')\n            return self.loop.run_until_complete(coro)[0]\n</code></pre>"},{"location":"reference/#futured.asynced.iter","title":"<code>iter(aiterable, loop=None)</code>  <code>staticmethod</code>","text":"<p>Wrap an asynchronous iterable into an iterator.</p> <p>Analogous to <code>asyncio.run</code> for coroutines.</p> Source code in <code>futured/__init__.py</code> <pre><code>@staticmethod\ndef iter(aiterable: AsyncIterable, loop=None):\n    \"\"\"Wrap an asynchronous iterable into an iterator.\n\n    Analogous to `asyncio.run` for coroutines.\n    \"\"\"\n    loop = loop or asyncio.new_event_loop()\n    anext = aiterable.__aiter__().__anext__\n    task = loop.create_task(anext())\n    while True:\n        try:\n            result = loop.run_until_complete(task)\n        except StopAsyncIteration:\n            return\n        task = loop.create_task(anext())\n        yield result\n</code></pre>"},{"location":"reference/#futured.asynced.run","title":"<code>run(*args, **kwargs)</code>","text":"<p>Synchronously call and run coroutine or asynchronous iterator.</p> Source code in <code>futured/__init__.py</code> <pre><code>def run(self: Callable, *args, **kwargs):\n    \"\"\"Synchronously call and run coroutine or asynchronous iterator.\"\"\"\n    coro = self(*args, **kwargs)\n    return asynced.iter(coro) if isinstance(coro, AsyncIterable) else asyncio.run(coro)\n</code></pre>"},{"location":"reference/#futured.decorated","title":"<code>futured.decorated(base, **decorators)</code>","text":"<p>Return subclass with decorated methods.</p> Source code in <code>futured/__init__.py</code> <pre><code>def decorated(base: type, **decorators: Callable) -&gt; type:\n    \"\"\"Return subclass with decorated methods.\"\"\"\n    namespace = {name: decorators[name](getattr(base, name)) for name in decorators}\n    return type(base.__name__, (base,), namespace)\n</code></pre>"},{"location":"reference/#futured.command","title":"<code>futured.command</code>","text":"<p>               Bases: <code>Popen</code></p> <p>Asynchronous subprocess with a future compatible interface.</p> Source code in <code>futured/__init__.py</code> <pre><code>class command(subprocess.Popen):\n    \"\"\"Asynchronous subprocess with a future compatible interface.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)\n\n    def check(self, args, stdout, stderr):\n        if self.returncode:\n            raise subprocess.CalledProcessError(self.returncode, args, stdout, stderr)\n        return stdout\n\n    @classmethod\n    async def coroutine(cls, *args, shell=False, **kwargs):\n        \"\"\"Create a subprocess coroutine, suitable for timeouts.\"\"\"\n        create = asyncio.create_subprocess_shell if shell else asyncio.create_subprocess_exec\n        self = await create(*args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)  # type: ignore\n        return cls.check(self, args, *(await self.communicate()))\n\n    def result(self, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"Return stdout or raise stderr.\"\"\"\n        return self.check(self.args, *self.communicate(**kwargs))\n\n    def pipe(self, *args, **kwargs) -&gt; 'command':\n        \"\"\"Pipe stdout to the next command's stdin.\"\"\"\n        return type(self)(*args, stdin=self.stdout, **kwargs)\n\n    def __or__(self, other: Iterable) -&gt; 'command':\n        \"\"\"Alias of [pipe][futured.command.pipe].\"\"\"\n        return self.pipe(*other)\n\n    def __iter__(self):\n        \"\"\"Return output lines.\"\"\"\n        return iter(self.result().splitlines())\n</code></pre>"},{"location":"reference/#futured.command.__iter__","title":"<code>__iter__()</code>","text":"<p>Return output lines.</p> Source code in <code>futured/__init__.py</code> <pre><code>def __iter__(self):\n    \"\"\"Return output lines.\"\"\"\n    return iter(self.result().splitlines())\n</code></pre>"},{"location":"reference/#futured.command.__or__","title":"<code>__or__(other)</code>","text":"<p>Alias of pipe.</p> Source code in <code>futured/__init__.py</code> <pre><code>def __or__(self, other: Iterable) -&gt; 'command':\n    \"\"\"Alias of [pipe][futured.command.pipe].\"\"\"\n    return self.pipe(*other)\n</code></pre>"},{"location":"reference/#futured.command.coroutine","title":"<code>coroutine(*args, shell=False, **kwargs)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Create a subprocess coroutine, suitable for timeouts.</p> Source code in <code>futured/__init__.py</code> <pre><code>@classmethod\nasync def coroutine(cls, *args, shell=False, **kwargs):\n    \"\"\"Create a subprocess coroutine, suitable for timeouts.\"\"\"\n    create = asyncio.create_subprocess_shell if shell else asyncio.create_subprocess_exec\n    self = await create(*args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)  # type: ignore\n    return cls.check(self, args, *(await self.communicate()))\n</code></pre>"},{"location":"reference/#futured.command.pipe","title":"<code>pipe(*args, **kwargs)</code>","text":"<p>Pipe stdout to the next command's stdin.</p> Source code in <code>futured/__init__.py</code> <pre><code>def pipe(self, *args, **kwargs) -&gt; 'command':\n    \"\"\"Pipe stdout to the next command's stdin.\"\"\"\n    return type(self)(*args, stdin=self.stdout, **kwargs)\n</code></pre>"},{"location":"reference/#futured.command.result","title":"<code>result(**kwargs)</code>","text":"<p>Return stdout or raise stderr.</p> Source code in <code>futured/__init__.py</code> <pre><code>def result(self, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"Return stdout or raise stderr.\"\"\"\n    return self.check(self.args, *self.communicate(**kwargs))\n</code></pre>"},{"location":"reference/#futured.forked","title":"<code>futured.forked(values, max_workers=0)</code>","text":"<p>Generate each value in its own child process and wait in the parent.</p> Source code in <code>futured/__init__.py</code> <pre><code>def forked(values: Iterable, max_workers: int = 0) -&gt; Iterator:\n    \"\"\"Generate each value in its own child process and wait in the parent.\"\"\"\n    max_workers = max_workers or os.cpu_count() or 1  # same default as ProcessPoolExecutor\n    workers: dict = {}\n\n    def wait():\n        pid, status = os.wait()\n        if pid in workers:\n            value = workers.pop(pid)\n            if status:\n                raise OSError(status, value)\n\n    for value in values:\n        while len(workers) &gt;= max_workers:\n            wait()\n        if pid := os.fork():\n            workers[pid] = value\n        else:  # pragma: no cover\n            yield value\n            os._exit(0)\n    while workers:\n        wait()\n</code></pre>"}]}